{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 各种常用sklearn算法实践特性分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. LR\n",
    "\n",
    "## 特点分析\n",
    "\n",
    "- 优点：\n",
    "    - 实现简单，需要配置的超参数少\n",
    "    - 训练速度快，支持多线程\n",
    "- 缺点：\n",
    "    - 模型的复杂度低，且无法通过超参数增大复杂度\n",
    "    - 对复杂的分类问题，很难达到非常高的分类性能\n",
    "    \n",
    "LR非常适合在不做任何配置的情况下做**baseline**，其他的复杂模型与LR baseline性能相比的增益才是有意义的。 \n",
    "\n",
    "## solver选择\n",
    "\n",
    "LR默认的优化求解器，不适用于大数据集，需要手动设置为solver='lbfgs'。\n",
    "不同solver的速度差别：\n",
    "\n",
    "- Liblinear，当前的默认solver，不支持多线程\n",
    "- lbfgs，后续版本的默认solver\n",
    "\n",
    "|训练数据量| Liblinear  | lbfgs |\n",
    "|--|--|--|\n",
    "| 1w | 6.97 | 9.3 |\n",
    "|10w| 105s | 7.8s|\n",
    "\n",
    "在数据量小的时候，可以使用默认的Liblinear，一旦数据量增大，必须切换到lbfgs，才能快速求解。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "clf_lr = LogisticRegression(random_state = 0, verbose=1, solver='lbfgs', n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 交叉验证方法\n",
    "\n",
    "K折交叉验证的优势：\n",
    "\n",
    "- 在没有测试集GT的情况下，可以更准确地评估模型的性能\n",
    "- 避免手动切分训练集和验证集，造成对训练集过拟合\n",
    "- 对k折的test predict结果去平均作为最终输出\n",
    "\n",
    "实现方式：\n",
    "\n",
    "- 用`KFold`划分训练集和验证集的index，手动写循环\n",
    "可以在循环中依次predict test结果，得到均值作为输出\n",
    "- 如果只需要模型在验证集上的score，可以直接用cross_val_score实现"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KFold实现\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "# Create the kfold object\n",
    "k_fold = KFold(n_splits = 3, shuffle = True, random_state = 50)\n",
    "\n",
    "def run_cv(clf):\n",
    "    '''\n",
    "    - clf，典型的sklearn分类器，具有fit/predict_proba 方法\n",
    "    - submission，输出的k折平均的测试集结果\n",
    "    '''\n",
    "    # 用于记录各轮的测试集分数,验证集score\n",
    "    test_prob = np.zeros(test_fill.shape[0])\n",
    "    val_scores = []\n",
    "    \n",
    "    for idx_train, idx_val in k_fold.split(train):\n",
    "        X_train, y_train = train[idx_train], train_labels[idx_train]\n",
    "        X_val, y_val = train[idx_val], train_labels[idx_val]\n",
    "        clf.fit(X_train, y_train)\n",
    "        val_score = roc_auc_score(y_val, clf.predict_proba(X_val)[:, 1])\n",
    "        val_scores.append(val_score)\n",
    "        test_prob += model.predict_proba(test_data)[:, 1] / k_fold.n_splits\n",
    "\n",
    "    submission = pd.DataFrame({'ID': test_ids, 'TARGET': test_prob})\n",
    "    print('mean val score: {}'.format(np.mean(val_scores)))\n",
    "    return submission\n",
    "\n",
    "submission = run_cv(clf)\n",
    "\n",
    "# 用StratifiedKFold 实现\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(n_splits=10,\n",
    "                        random_state=1).split(X_train, y_train)\n",
    "scores = []\n",
    "for k, (train, test) in enumerate(kfold):\n",
    "    pipe_lr.fit(X_train[train], y_train[train])\n",
    "    score = pipe_lr.score(X_train[test], y_train[test])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scores = cross_val_score(estimator=pipe_lr,\n",
    "                         X=X_train,\n",
    "                         y=y_train,\n",
    "                         cv=10,\n",
    "                         n_jobs=1)\n",
    "# 返回的 scores 是各类val分数的list\n",
    "print('CV accuracy: %.3f +/- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline 性能对比\n",
    "\n",
    "HomeCredit，用特征工程之后的数据，评测lgb最优模型与其他baseline分类器的性能差异。\n",
    "\n",
    "数据说明：\n",
    "\n",
    "- data_fe，特征工程生成的数据\n",
    "- data_fill，填充null，处理极大值之后的数据\n",
    "\n",
    "由于LGB可以直接输入带null的数据，而其他分类器需要对填充null，故统一用填充处理后的data_fill评测。\n",
    "\n",
    "评测结果：各个分类器的auc指标很低，最高仅为0.584。而使用data_fe训练的val auc在0.78。\n",
    "\n",
    "|    clf      |   test_score |   val_score |\n",
    "|:------------|-------------:|------------:|\n",
    "| lgbm_tune   |    nan       |    0.58447  |\n",
    "| lgbm_base   |    nan       |    0.5642   |\n",
    "| xgb         |    nan       |    0.54     |\n",
    "| lr_baseline |      0.54191 |    0.516605 |\n",
    "| mlp_32      |      0.5284  |    0.5142   |\n",
    "\n",
    "\n",
    "观点：\n",
    "\n",
    "- 强制imputer可能给数据带来了不利的噪音，例如大量的null用median填充，对于null比例很高的col，不合理\n",
    "- 总体上，lgb的学习能力是强于其他model。\n",
    "\n",
    "数据imputer的方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def impute_inf(df_data):\n",
    "    imputer = Imputer(strategy = 'median')\n",
    "    # replace inf as nan\n",
    "    df_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    # impute nan to median\n",
    "    df_data = imputer.fit_transform(df_data)\n",
    "    return df_data\n",
    "\n",
    "train_fill = impute_inf(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# lgb\n",
    "\n",
    "lgb对nan数据处理的机制是什么\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
